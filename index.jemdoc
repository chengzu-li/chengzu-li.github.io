# jemdoc: menu{MENU}{index.html}, nofooter
\n
== {{<span style="color:black;font-size:24pt;font-family:Songti SC">}}*Chengzu Li*{{</span>}}\n

~~~
{}{img_left}{assets/bio.jpg}{alt text}{400}{300}
\n
PhD student in Computation, Cognition and Language\n
[https://ltl.mmll.cam.ac.uk/ Language Technology Lab]\n
[https://www.cam.ac.uk/ University of Cambridge]


\[[cl917@cam.ac.uk Email]\]
\[[https://github.com/chengzu-li Github]\] \[[https://scholar.google.com/citations?user=t_Bwt70AAAAJ Google Scholar]\] \[[https://www.semanticscholar.org/author/Chengzu-Li/2155795167 Semantic Scholar]\] \[[assets/CV_PhD_Chengzu.pdf CV]\]
~~~

== About me
I am a second-year PhD student in Computation, Cognition and Language at [https://ltl.mmll.cam.ac.uk/ Language Technology Lab] in the University of Cambridge, supervised by [https://sites.google.com/site/ivanvulic/ Dr. Ivan VuliÄ‡] and [https://sergebelongie.github.io/ Prof. Serge Belongie].
My research is supported by Cambridge Trust.
I am a member of [https://www.jesus.cam.ac.uk/ Jesus College].

Before starting my PhD, I received my MPhil degree in Advanced Computer Science at the Department of Computer Science, supervised by [https://www.cl.cam.ac.uk/~sht25/ Prof. Simone Teufel], supported by Cambridge Trust.
I was an undergraduate student in Automation at [http://en.xjtu.edu.cn/ Xi'an Jiaotong University].


== Research
I'm generally interested in different topics in NLP and machine learning. My research interests include language grounding and reasoning, especially in multimodality (eg. structural knowledge, image, etc.).
I am currently exploring and focusing on:
- Multimodal spatial reasoning with vision and language \[[https://topviewrs.github.io/ TopViewRS]\]
- Grounding large language models with Multimodal Chain-of-Thought \[[https://arxiv.org/abs/2501.07542v1 MVoT]\]
- Multimodal thinking models.

I'm also interested in the potential downstream application scenarios of multimodal reasoning.

== Education
- PhD (Probationary) in Computation, Cognition and Language, [https://ltl.mmll.cam.ac.uk/ Language Technology Lab], University of Cambridge, 2023 \- now
- Master of Philosophy in Advanced Computer Science, University of Cambridge, 2022 \- 2023
-- Graduation with Distinction
- Bachelor of Engineering in Automation, Xi'an Jiaotong University, 2018 \- 2022
-- Graduate with Distinction (91.88/100)
-- Minor in Fintech (China Construction Bank \- XJTU Fintech Elite Class)


== Publications 
(\*: equal contribution)

*Preprints*
- ðŸ”¥[https://arxiv.org/abs/2501.07542v1 Imagine while Reasoning in Space: Multimodal Visualization-of-Thought]\n
*Chengzu Li*\*, Wenshan Wu\*, Huanyu Zhang, Yan Xia, Shaoguang Mao, Li Dong, Ivan VuliÄ‡, Furu Wei \n
arXiv. \[[https://arxiv.org/pdf/2501.07542v1 pdf]\] \[[https://github.com/chengzu-li/MVoT code]\]

- ðŸ”¥[https://arxiv.org/abs/2504.15037 A Call for New Recipes to Enhance Spatial Reasoning in MLLMs]\n
Huanyu Zhang\*, *Chengzu Li*\*, Wenshan Wu, Shaoguang Mao, Yan Xia, Ivan VuliÄ‡, Zhang Zhang, Liang Wang, Tieniu Tan, Furu Wei \n
arXiv. \[[https://arxiv.org/pdf/2504.15037 pdf]\] 

*2024*
- [https://arxiv.org/abs/2406.02537 TopViewRS: Vision-Language Models as Top-View Spatial Reasoners]\n
*Chengzu Li*\*, Caiqi Zhang\*, Han Zhou, Nigel Collier, Anna Korhonen, Ivan VuliÄ‡ \n
EMNLP 2024, main (oral). \[[https://topviewrs.github.io/ project website]\] \[[https://arxiv.org/abs/2406.02537 pdf]\] \[[https://github.com/cambridgeltl/topviewrs code]\] \[[https://huggingface.co/datasets/chengzu/topviewrs data]\]

- [https://arxiv.org/abs/2312.13772 On Task Performance and Model Calibration with Supervised and Self-Ensembled In-Context Learning]\n
*Chengzu Li*, Han Zhou, Goran GlavaÅ¡, Anna Korhonen, Ivan VuliÄ‡. \n
ICLR 2024 Workshop on Reliable and Responsible Foundation Models. \[[https://arxiv.org/abs/2312.13772 pdf]\] \[[https://github.com/cambridgeltl/ensembled-sicl code]\]

- [https://arxiv.org/abs/2403.19603 Semantic Map-based Generation of Navigation Instructions]\n
*Chengzu Li*, Chao Zhang, Simone Teufel, Rama Sanand Doddipatla, Svetlana Stoyanchev.\n
COLING-LREC 2024. \[[https://arxiv.org/abs/2403.19603 pdf]\] \[[https://github.com/chengzu-li/VLGen code]\]

*2023*

- [https://arxiv.org/abs/2305.13917 Generating Data for Symbolic Language with Large Language Models]\n
Jiacheng Ye, *Chengzu Li*, Lingpeng Kong, Tao Yu.\n
EMNLP 2023, main. \[[https://arxiv.org/abs/2305.13917 pdf]\] \[[https://github.com/HKUNLP/SymGen code]\]

- [https://arxiv.org/abs/2210.02875 Binding Language Models in Symbolic Languages]\n
Zhoujun Cheng, Tianbao Xie, Peng Shi, *Chengzu Li*, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, Tao Yu. \n
ICLR 2023 (spotlight). \[[https://arxiv.org/abs/2210.02875 pdf]\] \[[https://github.com/HKUNLP/Binder code]\]

*2022*

- [https://arxiv.org/abs/2201.05966 UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models]\n
Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, *Chengzu Li*, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, Tao Yu. \n
EMNLP 2022, main (oral). \[[https://arxiv.org/abs/2201.05966 pdf]\] \[[https://github.com/hkunlp/unifiedskg code]\]


== Internships
- Jun. 2024 - Dec. 2024
\nResearch Intern, [https://www.microsoft.com/en-us/research/group/general-artificial-intelligence/ GenAI Group, Microsoft Research].
\nMentor: [https://scholar.google.com/citations?user=AwANOsQAAAAJ Wenshan Wu].
\nResearch on Multimodal Spatial Reasoning.

- Jan. 2023 - July 2023
\nResearch Intern, [https://www.toshiba.eu/pages/eu/Cambridge-Research-Laboratory/ Toshiba Cambridge Research].
\nMentor: [https://www.linkedin.com/in/svetlana-stoyanchev/?originalSubdomain=uk Svetlana Stoyanchev], [https://sites.google.com/site/cschaozhang/ Chao Zhang], [https://scholar.google.co.uk/citations?user=xxd3HZsAAAAJ&hl=en Rama Sanand Doddipatla] and [https://www.cl.cam.ac.uk/~sht25/ Prof. Simone Teufel].
\nResearch on Generating Instructions for Robot Navigation as the MPhil thesis.

- Oct. 2021 - Jan. 2022
\nResearch Intern, Shanghai AI Lab.
\nMentor: [https://ikekonglp.github.io/ Lingpeng Kong].
\nResearch on Structural Knowledge Grounding.

- June 2021 - Oct. 2022
\nResearch Intern, [https://hkunlp.github.io/ HKUNLP].
\nMentor: [https://taoyds.github.io/ Tao Yu] and [https://ikekonglp.github.io/ Lingpeng Kong].
\nWorked on Structural Knowledge Grounding, Semantic Parsing and Neural-Symbolic Reasoning.

- July 2020 - Aug. 2020
\nEngineer Intern, Dianchu Technology.
\nWorked on machine learning engineering.


== Selected Honors & Awards
- Scholar of Jesus College, Cambridge (for outstanding academic performance), 2024.
- PhD Scholarship, Cambridge Trust, 2023.
- Master Scholarship, Cambridge Trust, 2022.
- National Scholarship (1\%), Ministry of Education of China, 2019.


== Media Coverage and Presentations
- [https://twimlai.com/podcast/twimlai/imagine-while-reasoning-in-space-multimodal-visualization-of-thought/ The TWIML AI Podcast with Sam Charrington]
- [https://spectrum.ieee.org/visual-reasoning-in-ai IEEE Spectrum, ``Thinking" Visually Boosts AI Problem Solving]
- [https://www.youtube.com/watch?v=Y78aSGJNeXY BMVA: Trustworthy Multimodal Learning with Foundation Models]
